# éƒ¨ç½²æµç¨‹å’Œ CI/CD ç­–ç•¥

## æ„å»ºå’Œéƒ¨ç½²ç¯å¢ƒ

### ç¯å¢ƒåˆ†å±‚
```yaml
# ç¯å¢ƒé…ç½®å±‚çº§
environments:
  development:
    description: "æœ¬åœ°å¼€å‘ç¯å¢ƒ"
    database: "æœ¬åœ° PostgreSQL"
    external_apis: "Mock æœåŠ¡"
    debug: true
    
  staging:
    description: "é¢„å‘å¸ƒæµ‹è¯•ç¯å¢ƒ"
    database: "æµ‹è¯•æ•°æ®åº“"
    external_apis: "æµ‹è¯• API"
    debug: false
    
  production:
    description: "ç”Ÿäº§ç¯å¢ƒ"
    database: "ç”Ÿäº§æ•°æ®åº“"
    external_apis: "ç”Ÿäº§ API"
    debug: false
    monitoring: "å…¨é¢ç›‘æ§"
```

### Docker å®¹å™¨åŒ–
```dockerfile
# å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–
FROM node:18-alpine AS base
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

FROM node:18-alpine AS build
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM node:18-alpine AS runtime
WORKDIR /app
COPY --from=base /app/node_modules ./node_modules
COPY --from=build /app/.next ./.next
COPY --from=build /app/public ./public
COPY --from=build /app/package.json ./package.json

EXPOSE 3000
CMD ["npm", "start"]
```

## CI/CD ç®¡é“é…ç½®

### GitHub Actions å·¥ä½œæµ
```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run type checking
        run: npm run type-check
        
      - name: Run linting
        run: npm run lint
        
      - name: Run unit tests
        run: npm run test:unit
        
      - name: Run integration tests
        run: npm run test:integration
        
      - name: Generate test coverage
        run: npm run test:coverage
        
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3

  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Run security audit
        run: npm audit --audit-level high
        
      - name: Scan for vulnerabilities
        uses: securecodewarrior/github-action-add-sarif@v1
        with:
          sarif-file: 'security-scan-results.sarif'

  build:
    needs: [test, security]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Build Docker image
        run: |
          docker build -t smart-travel-assistant:${{ github.sha }} .
          docker tag smart-travel-assistant:${{ github.sha }} smart-travel-assistant:latest
          
      - name: Push to registry
        if: github.ref == 'refs/heads/main'
        run: |
          echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
          docker push smart-travel-assistant:${{ github.sha }}
          docker push smart-travel-assistant:latest

  deploy-staging:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: staging
    steps:
      - name: Deploy to staging
        run: |
          # éƒ¨ç½²åˆ°é¢„å‘å¸ƒç¯å¢ƒçš„è„šæœ¬
          ./scripts/deploy-staging.sh
          
  deploy-production:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
      - name: Deploy to production
        run: |
          # éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒçš„è„šæœ¬
          ./scripts/deploy-production.sh
```

### éƒ¨ç½²è„šæœ¬æ ‡å‡†
```bash
#!/bin/bash
# scripts/deploy.sh

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# ç¯å¢ƒå˜é‡éªŒè¯
validate_environment() {
    local required_vars=(
        "DATABASE_URL"
        "JWT_SECRET"
        "DEEPSEEK_API_KEY"
        "GAODE_API_KEY"
    )
    
    for var in "${required_vars[@]}"; do
        if [[ -z "${!var}" ]]; then
            echo "é”™è¯¯: ç¯å¢ƒå˜é‡ $var æœªè®¾ç½®"
            exit 1
        fi
    done
}

# æ•°æ®åº“è¿ç§»
run_migrations() {
    echo "è¿è¡Œæ•°æ®åº“è¿ç§»..."
    npm run db:migrate
    
    if [[ $? -ne 0 ]]; then
        echo "æ•°æ®åº“è¿ç§»å¤±è´¥"
        exit 1
    fi
}

# å¥åº·æ£€æŸ¥
health_check() {
    local max_attempts=30
    local attempt=1
    
    while [[ $attempt -le $max_attempts ]]; do
        if curl -f http://localhost:3000/api/health; then
            echo "åº”ç”¨å¯åŠ¨æˆåŠŸ"
            return 0
        fi
        
        echo "ç­‰å¾…åº”ç”¨å¯åŠ¨... ($attempt/$max_attempts)"
        sleep 10
        ((attempt++))
    done
    
    echo "åº”ç”¨å¯åŠ¨å¤±è´¥"
    exit 1
}

# å›æ»šæœºåˆ¶
rollback() {
    echo "æ‰§è¡Œå›æ»š..."
    docker-compose down
    docker-compose up -d --scale app=0
    docker tag smart-travel-assistant:previous smart-travel-assistant:latest
    docker-compose up -d
}

# ä¸»éƒ¨ç½²æµç¨‹
main() {
    validate_environment
    
    # å¤‡ä»½å½“å‰ç‰ˆæœ¬
    docker tag smart-travel-assistant:latest smart-travel-assistant:previous
    
    # æ‹‰å–æ–°é•œåƒ
    docker pull smart-travel-assistant:latest
    
    # è¿è¡Œæ•°æ®åº“è¿ç§»
    run_migrations
    
    # æ»šåŠ¨æ›´æ–°
    docker-compose up -d --no-deps app
    
    # å¥åº·æ£€æŸ¥
    if ! health_check; then
        rollback
        exit 1
    fi
    
    echo "éƒ¨ç½²æˆåŠŸå®Œæˆ"
}

main "$@"
```

## ç¯å¢ƒé…ç½®ç®¡ç†

### é…ç½®æ–‡ä»¶ç»“æ„
```typescript
// config/environments.ts
interface EnvironmentConfig {
  database: DatabaseConfig;
  redis: RedisConfig;
  external: ExternalServicesConfig;
  monitoring: MonitoringConfig;
  security: SecurityConfig;
}

const environments: Record<string, EnvironmentConfig> = {
  development: {
    database: {
      url: process.env.DEV_DATABASE_URL,
      ssl: false,
      logging: true
    },
    redis: {
      url: process.env.DEV_REDIS_URL,
      keyPrefix: 'dev:'
    },
    external: {
      deepseek: {
        baseUrl: 'https://api.deepseek.com',
        timeout: 30000,
        retries: 3
      },
      gaode: {
        baseUrl: 'https://restapi.amap.com',
        timeout: 15000,
        retries: 2
      }
    },
    monitoring: {
      enabled: false,
      logLevel: 'debug'
    },
    security: {
      corsOrigins: ['http://localhost:3000'],
      rateLimiting: false
    }
  },
  
  production: {
    database: {
      url: process.env.DATABASE_URL,
      ssl: true,
      logging: false,
      pool: {
        min: 5,
        max: 20
      }
    },
    redis: {
      url: process.env.REDIS_URL,
      keyPrefix: 'prod:',
      cluster: true
    },
    external: {
      deepseek: {
        baseUrl: 'https://api.deepseek.com',
        timeout: 30000,
        retries: 3,
        circuitBreaker: true
      },
      gaode: {
        baseUrl: 'https://restapi.amap.com',
        timeout: 15000,
        retries: 2,
        circuitBreaker: true
      }
    },
    monitoring: {
      enabled: true,
      logLevel: 'error',
      metrics: true,
      tracing: true
    },
    security: {
      corsOrigins: ['https://travel-assistant.com'],
      rateLimiting: true,
      helmet: true
    }
  }
};
```

### ç¯å¢ƒå˜é‡æ¨¡æ¿
```bash
# .env.example
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://username:password@localhost:5432/travel_assistant
DB_SSL_CA=path/to/ca-certificate.crt

# Redis é…ç½®
REDIS_URL=redis://localhost:6379

# JWT é…ç½®
JWT_SECRET=your-super-secret-jwt-key-at-least-32-characters
JWT_REFRESH_SECRET=your-refresh-token-secret

# å¤–éƒ¨æœåŠ¡ API å¯†é’¥
DEEPSEEK_API_KEY=your-deepseek-api-key
GAODE_API_KEY=your-gaode-map-api-key

# åŠ å¯†å¯†é’¥
ENCRYPTION_KEY=your-32-byte-encryption-key

# ç›‘æ§å’Œæ—¥å¿—
LOG_LEVEL=info
SENTRY_DSN=your-sentry-dsn

# é‚®ä»¶æœåŠ¡
SMTP_HOST=smtp.example.com
SMTP_PORT=587
SMTP_USER=your-email@example.com
SMTP_PASS=your-email-password

# æ–‡ä»¶å­˜å‚¨
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_S3_BUCKET=your-s3-bucket-name
AWS_REGION=us-east-1
```

## ç›‘æ§å’Œæ—¥å¿—

### åº”ç”¨ç›‘æ§é…ç½®
```typescript
// monitoring/setup.ts
import { createPrometheusMetrics } from './prometheus';
import { setupSentry } from './sentry';
import { configureWinston } from './winston';

export const setupMonitoring = () => {
  // Prometheus æŒ‡æ ‡æ”¶é›†
  const metrics = createPrometheusMetrics({
    httpRequests: 'http_requests_total',
    httpDuration: 'http_request_duration_seconds',
    dbConnections: 'database_connections_active',
    externalApiCalls: 'external_api_calls_total'
  });
  
  // Sentry é”™è¯¯è¿½è¸ª
  setupSentry({
    dsn: process.env.SENTRY_DSN,
    environment: process.env.NODE_ENV,
    tracesSampleRate: process.env.NODE_ENV === 'production' ? 0.1 : 1.0
  });
  
  // Winston æ—¥å¿—é…ç½®
  const logger = configureWinston({
    level: process.env.LOG_LEVEL || 'info',
    format: process.env.NODE_ENV === 'production' ? 'json' : 'simple',
    transports: [
      'console',
      ...(process.env.NODE_ENV === 'production' ? ['file', 'cloudwatch'] : [])
    ]
  });
  
  return { metrics, logger };
};
```

### å¥åº·æ£€æŸ¥ç«¯ç‚¹
```typescript
// api/health/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { checkDatabaseHealth } from '@/lib/database';
import { checkRedisHealth } from '@/lib/redis';
import { checkExternalServices } from '@/lib/external-services';

export async function GET(request: NextRequest) {
  const checks = await Promise.allSettled([
    checkDatabaseHealth(),
    checkRedisHealth(),
    checkExternalServices()
  ]);
  
  const health = {
    status: 'healthy',
    timestamp: new Date().toISOString(),
    version: process.env.APP_VERSION || 'unknown',
    checks: {
      database: checks[0].status === 'fulfilled' ? 'healthy' : 'unhealthy',
      redis: checks[1].status === 'fulfilled' ? 'healthy' : 'unhealthy',
      external: checks[2].status === 'fulfilled' ? 'healthy' : 'unhealthy'
    }
  };
  
  const isHealthy = Object.values(health.checks).every(status => status === 'healthy');
  health.status = isHealthy ? 'healthy' : 'unhealthy';
  
  return NextResponse.json(health, {
    status: isHealthy ? 200 : 503
  });
}
```

## æ€§èƒ½ä¼˜åŒ–

### æ„å»ºä¼˜åŒ–
```javascript
// next.config.js
/** @type {import('next').NextConfig} */
const nextConfig = {
  // ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–
  compiler: {
    removeConsole: process.env.NODE_ENV === 'production'
  },
  
  // å›¾ç‰‡ä¼˜åŒ–
  images: {
    domains: ['your-cdn-domain.com'],
    formats: ['image/webp', 'image/avif']
  },
  
  // å‹ç¼©é…ç½®
  compress: true,
  
  // å®éªŒæ€§åŠŸèƒ½
  experimental: {
    serverComponentsExternalPackages: ['@prisma/client']
  },
  
  // Webpack ä¼˜åŒ–
  webpack: (config, { isServer }) => {
    if (!isServer) {
      config.resolve.fallback = {
        fs: false,
        net: false,
        tls: false
      };
    }
    
    // Bundle åˆ†æ
    if (process.env.ANALYZE === 'true') {
      const { BundleAnalyzerPlugin } = require('webpack-bundle-analyzer');
      config.plugins.push(
        new BundleAnalyzerPlugin({
          analyzerMode: 'static',
          openAnalyzer: false
        })
      );
    }
    
    return config;
  }
};

module.exports = nextConfig;
```

### ç¼“å­˜ç­–ç•¥
```typescript
// lib/cache-strategy.ts
export const cacheConfig = {
  // é™æ€èµ„æºç¼“å­˜
  static: {
    maxAge: 31536000, // 1å¹´
    staleWhileRevalidate: 86400 // 1å¤©
  },
  
  // API å“åº”ç¼“å­˜
  api: {
    travelPlans: {
      maxAge: 3600, // 1å°æ—¶
      tags: ['travel-plans']
    },
    userPreferences: {
      maxAge: 1800, // 30åˆ†é’Ÿ
      tags: ['user-preferences']
    },
    mapData: {
      maxAge: 86400, // 1å¤©
      tags: ['map-data']
    }
  },
  
  // æ•°æ®åº“æŸ¥è¯¢ç¼“å­˜
  database: {
    userProfiles: 900, // 15åˆ†é’Ÿ
    travelHistory: 1800, // 30åˆ†é’Ÿ
    systemConfig: 3600 // 1å°æ—¶
  }
};
```

## å®‰å…¨éƒ¨ç½²æ£€æŸ¥

### éƒ¨ç½²å‰å®‰å…¨æ£€æŸ¥æ¸…å•
```bash
#!/bin/bash
# scripts/security-check.sh

echo "æ‰§è¡Œéƒ¨ç½²å‰å®‰å…¨æ£€æŸ¥..."

# 1. ç¯å¢ƒå˜é‡æ£€æŸ¥
check_env_vars() {
    echo "æ£€æŸ¥æ•æ„Ÿç¯å¢ƒå˜é‡..."
    
    if [[ -z "$JWT_SECRET" ]] || [[ ${#JWT_SECRET} -lt 32 ]]; then
        echo "âŒ JWT_SECRET æœªè®¾ç½®æˆ–é•¿åº¦ä¸è¶³32å­—ç¬¦"
        return 1
    fi
    
    if [[ -z "$ENCRYPTION_KEY" ]] || [[ ${#ENCRYPTION_KEY} -lt 32 ]]; then
        echo "âŒ ENCRYPTION_KEY æœªè®¾ç½®æˆ–é•¿åº¦ä¸è¶³32å­—ç¬¦"
        return 1
    fi
    
    echo "âœ… ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡"
}

# 2. ä¾èµ–å®‰å…¨æ£€æŸ¥
check_dependencies() {
    echo "æ£€æŸ¥ä¾èµ–åŒ…å®‰å…¨æ€§..."
    
    npm audit --audit-level high
    if [[ $? -ne 0 ]]; then
        echo "âŒ å‘ç°é«˜å±å®‰å…¨æ¼æ´"
        return 1
    fi
    
    echo "âœ… ä¾èµ–åŒ…å®‰å…¨æ£€æŸ¥é€šè¿‡"
}

# 3. ä»£ç å®‰å…¨æ‰«æ
check_code_security() {
    echo "æ‰§è¡Œä»£ç å®‰å…¨æ‰«æ..."
    
    # ä½¿ç”¨ semgrep æˆ–å…¶ä»–å®‰å…¨æ‰«æå·¥å…·
    if command -v semgrep &> /dev/null; then
        semgrep --config=auto --error .
        if [[ $? -ne 0 ]]; then
            echo "âŒ ä»£ç å®‰å…¨æ‰«æå‘ç°é—®é¢˜"
            return 1
        fi
    fi
    
    echo "âœ… ä»£ç å®‰å…¨æ‰«æé€šè¿‡"
}

# 4. é…ç½®å®‰å…¨æ£€æŸ¥
check_config_security() {
    echo "æ£€æŸ¥é…ç½®å®‰å…¨æ€§..."
    
    # æ£€æŸ¥æ˜¯å¦ç¦ç”¨äº†è°ƒè¯•æ¨¡å¼
    if [[ "$NODE_ENV" == "production" ]] && [[ "$DEBUG" == "true" ]]; then
        echo "âŒ ç”Ÿäº§ç¯å¢ƒä¸åº”å¯ç”¨è°ƒè¯•æ¨¡å¼"
        return 1
    fi
    
    # æ£€æŸ¥ CORS é…ç½®
    if [[ "$CORS_ORIGIN" == "*" ]]; then
        echo "âŒ CORS ä¸åº”å…è®¸æ‰€æœ‰åŸŸå"
        return 1
    fi
    
    echo "âœ… é…ç½®å®‰å…¨æ£€æŸ¥é€šè¿‡"
}

# æ‰§è¡Œæ‰€æœ‰æ£€æŸ¥
main() {
    check_env_vars && \
    check_dependencies && \
    check_code_security && \
    check_config_security
    
    if [[ $? -eq 0 ]]; then
        echo "ğŸ‰ æ‰€æœ‰å®‰å…¨æ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥éƒ¨ç½²"
        exit 0
    else
        echo "âŒ å®‰å…¨æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤é—®é¢˜åé‡è¯•"
        exit 1
    fi
}

main "$@"
```

## å›æ»šå’Œç¾éš¾æ¢å¤

### è‡ªåŠ¨å›æ»šæœºåˆ¶
```bash
#!/bin/bash
# scripts/rollback.sh

BACKUP_RETENTION_DAYS=7

# æ•°æ®åº“å¤‡ä»½å›æ»š
rollback_database() {
    local backup_file=$1
    
    echo "å›æ»šæ•°æ®åº“åˆ°å¤‡ä»½: $backup_file"
    
    # åˆ›å»ºå½“å‰çŠ¶æ€å¤‡ä»½
    pg_dump $DATABASE_URL > "rollback_backup_$(date +%Y%m%d_%H%M%S).sql"
    
    # æ¢å¤åˆ°æŒ‡å®šå¤‡ä»½
    psql $DATABASE_URL < "$backup_file"
    
    if [[ $? -eq 0 ]]; then
        echo "âœ… æ•°æ®åº“å›æ»šæˆåŠŸ"
    else
        echo "âŒ æ•°æ®åº“å›æ»šå¤±è´¥"
        exit 1
    fi
}

# åº”ç”¨ç‰ˆæœ¬å›æ»š
rollback_application() {
    local previous_version=$1
    
    echo "å›æ»šåº”ç”¨åˆ°ç‰ˆæœ¬: $previous_version"
    
    # åœæ­¢å½“å‰æœåŠ¡
    docker-compose down
    
    # åˆ‡æ¢åˆ°ä¹‹å‰ç‰ˆæœ¬
    docker tag "smart-travel-assistant:$previous_version" smart-travel-assistant:latest
    
    # é‡å¯æœåŠ¡
    docker-compose up -d
    
    # å¥åº·æ£€æŸ¥
    sleep 30
    if curl -f http://localhost:3000/api/health; then
        echo "âœ… åº”ç”¨å›æ»šæˆåŠŸ"
    else
        echo "âŒ åº”ç”¨å›æ»šå¤±è´¥"
        exit 1
    fi
}

# æ¸…ç†æ—§å¤‡ä»½
cleanup_old_backups() {
    echo "æ¸…ç† $BACKUP_RETENTION_DAYS å¤©å‰çš„å¤‡ä»½..."
    find ./backups -name "*.sql" -mtime +$BACKUP_RETENTION_DAYS -delete
    find ./backups -name "*.tar.gz" -mtime +$BACKUP_RETENTION_DAYS -delete
}

main() {
    local action=${1:-"app"}
    local target=${2:-"previous"}
    
    case $action in
        "database")
            rollback_database "$target"
            ;;
        "app")
            rollback_application "$target"
            ;;
        "full")
            rollback_database "$target.sql"
            rollback_application "$target"
            ;;
        "cleanup")
            cleanup_old_backups
            ;;
        *)
            echo "ç”¨æ³•: $0 [database|app|full|cleanup] [target]"
            exit 1
            ;;
    esac
}

main "$@"
```

## éƒ¨ç½²æ£€æŸ¥æ¸…å•

### éƒ¨ç½²å‰æ£€æŸ¥
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ˆå•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€E2Eæµ‹è¯•ï¼‰
- [ ] ä»£ç å®¡æŸ¥å®Œæˆ
- [ ] å®‰å…¨æ‰«æé€šè¿‡
- [ ] æ€§èƒ½æµ‹è¯•é€šè¿‡
- [ ] æ•°æ®åº“è¿ç§»è„šæœ¬å‡†å¤‡å°±ç»ª
- [ ] ç¯å¢ƒå˜é‡é…ç½®æ­£ç¡®
- [ ] ç›‘æ§å’Œå‘Šè­¦é…ç½®å®Œæˆ
- [ ] å›æ»šè®¡åˆ’å‡†å¤‡å°±ç»ª

### éƒ¨ç½²åéªŒè¯
- [ ] åº”ç”¨å¥åº·æ£€æŸ¥é€šè¿‡
- [ ] å…³é”®åŠŸèƒ½éªŒè¯å®Œæˆ
- [ ] æ€§èƒ½æŒ‡æ ‡æ­£å¸¸
- [ ] é”™è¯¯ç‡åœ¨å¯æ¥å—èŒƒå›´å†…
- [ ] ç›‘æ§æ•°æ®æ­£å¸¸æ”¶é›†
- [ ] æ—¥å¿—è¾“å‡ºæ­£å¸¸
- [ ] å¤–éƒ¨æœåŠ¡è¿æ¥æ­£å¸¸
- [ ] ç”¨æˆ·åé¦ˆæ”¶é›†æœºåˆ¶æ­£å¸¸